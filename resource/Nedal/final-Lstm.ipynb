{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08de851c",
   "metadata": {},
   "source": [
    "# FINTECH BOOTCAMP - PROJECT 2\n",
    "## Group 2 Notebook\n",
    "---\n",
    "By applying machine learning models, we examine (1) if selective technical indicators could predict the stock direction with statistically significant level (2) Which model is the best (3) Whether we could optimize the model (4) Which time frame the model could generate the best result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fdbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial import all libraries and dependencies\n",
    "import yfinance as yf\n",
    "import matplotlib.dates as mdates\n",
    "import panel as pn\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from finta import TA\n",
    "# from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore wanrings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3f2b7",
   "metadata": {},
   "source": [
    "### I. DATA FETCHING AND CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the instruments to download data of a stock/ETF .\n",
    "tickers = [\"AAPL\", \"TSLA\", \"MSFT\", \"SPY\", \"...\"] # to be decided\n",
    "\n",
    "# Fetch SPY Data from 1/1/2017 until 12/31/2021 and choosing a interval\n",
    "start_date = datetime.date(2017,1,1)\n",
    "end_date = datetime.date(2021,12,31)\n",
    "interval = '1d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3035b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pandas_reader.data.DataReader to load the desired data.\n",
    "yf.Tickers(tickers[0])\n",
    "panel_data = yf.download(tickers[0], start = start_date, end = end_date, interval = interval)\n",
    "\n",
    "# Checkout the data type\n",
    "type(panel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data\n",
    "panel_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data description and check if null\n",
    "def data_description(df):\n",
    "    print(\"Data Information\")\n",
    "    print(df.info())\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe61e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description(panel_data) # if 0 null and OHLC is floating and Volumne is int, then data is clean to proceed to part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dae839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF data is note clean then dropping null or convert datatype\n",
    "# def data_cleaning(df):\n",
    "#     df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07070f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to ohlcv dataframe to be ready for finta\n",
    "def ohlcv(df):\n",
    "    del(df['Close'])\n",
    "    df = df.rename(columns = {\"Open\": \"open\",'High' : 'high', 'Low' : \"low\", \"Adj Close\": \"close\", 'Volume': 'volume'},inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv(panel_data)\n",
    "panel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199302ed",
   "metadata": {},
   "source": [
    "### II. DATA PROCESSING AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeframe for prediction\n",
    "time_frame = [3,5,7]\n",
    "\n",
    "# Identify stock direction\n",
    "def stock_direction(df, days):# days is time frame\n",
    "    direction = (df['close'].shift(-days) > df['close'])\n",
    "    direction = direction.iloc[:-days]\n",
    "    return direction.astype(int) #return y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_direction(panel_data,time_frame[0]) # y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Finta calculate technical indicators\n",
    "# Define key window to calculate for technical analysis \n",
    "window = [5,14,21,50]\n",
    "def technical_indicators (df): # https://github.com/peerchemist/finta/blob/master/finta/finta.py\n",
    "    x = pd.DataFrame()\n",
    "    for n in range(len(window)) :  ### LOOPING DOES NOT SHOW(?)\n",
    "        a = TA.BBANDS(df,window[n])\n",
    "        b = TA.RSI(df,window[n])\n",
    "        c = TA.PIVOT_FIB(df)\n",
    "        d = TA.OBV(df)\n",
    "        e = TA.SMA(df,window[n])\n",
    "        f = TA.EMA(df,window[n])\n",
    "        g = TA.ROC(df,window[n])\n",
    "        k = TA.WILLIAMS(df,window[n])\n",
    "        temp = pd.concat([a,b,c,d,e,f,g,k],axis = 1)\n",
    "        x = pd.concat([x,temp],axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56819fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_indicators(panel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consol_data(df,days):\n",
    "    consol_data = technical_indicators(df)\n",
    "    consol_data[\"direction\"] = stock_direction(df,days)\n",
    "    consol_data.dropna(inplace = True)\n",
    "    return consol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f011eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = consol_data(panel_data,time_frame[0])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f5fb0",
   "metadata": {},
   "source": [
    "### III. CHOOSING MODELS AND TRAINING MODEL (INDIVIDUAL WORK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2f097",
   "metadata": {},
   "source": [
    "#### 1. Model 1......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e5125",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20639b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 30\n",
    "# parsing the most important featurs (S1,S4,21 period SMA,14 perioid RSI,BB LOWER,ROC) \n",
    "feature_column = [8,26,44,62,50,21,2,20,38,56,16,34,52,5,23,41,59]\n",
    "target_column =[72]\n",
    "X, y = window_data(data, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83403a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1747c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "split=int(0.7 * len(X))\n",
    "X_train=X[: split]\n",
    "X_test=X[split :]\n",
    "y_train=y[: split]\n",
    "y_test=y[split :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4017197",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a9a63",
   "metadata": {},
   "source": [
    "### Reshape the X and y to be in 2d array as the  MinMaxScaler only accept 2d arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c11361",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_test.shape\n",
    "X_test=X_test.reshape((nsamples,nx*ny))\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e7e1c",
   "metadata": {},
   "source": [
    "##### Why should we scale target variables in regression problems?\n",
    "\n",
    "###### A target variable with a large spread of values, in turn, may result in large error gradient values causing weight values to change dramatically, making the learning process unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd599f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the training feature data X_train\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the training target data y_train\n",
    "scaler.fit(y_train)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080e093",
   "metadata": {},
   "source": [
    "### Reducing Dimensions Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b7cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensions to 3 principal components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_train= pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ddcc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f8fbb",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257cfc48",
   "metadata": {},
   "source": [
    "### Build and Train the LSTM RNN\n",
    "\n",
    "In this section, we will design a custom LSTM RNN in Keras and fit (train) it using the training data we defined.\n",
    "\n",
    "You we need to:\n",
    "\n",
    "1. Define the model architecture in Keras.\n",
    "\n",
    "2. Compile the model.\n",
    "\n",
    "3. Fit the model with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2604034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e594fc8",
   "metadata": {},
   "source": [
    "* `Dropout`: Dropout is a regularization technique for reducing overfitting in neural networks. This type of layer applies the dropout technique to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ead508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 30\n",
    "dropout_fraction = 0.5\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1)))\n",
    "    \n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85473801",
   "metadata": {},
   "source": [
    "#### Compile the LSTM RNN Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", metrics=\"accuracy\", loss = \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511272e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90f154",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='accuracy',\n",
    "                               patience=10,\n",
    "                               mode='max',\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train ,y_train, epochs=100, shuffle=False, batch_size=16, verbose=1,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca788a7",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9657a6d",
   "metadata": {},
   "source": [
    "## Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f9eb70",
   "metadata": {},
   "source": [
    "### Making Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95332ff8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f0f4f",
   "metadata": {},
   "source": [
    "### Creat DataFrame for Predicted Vs. Real Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score\n",
    "from IPython.display import display\n",
    "\n",
    "THRESHOLD = [0.4,0.5,0.52 ,0.55, 0.57, 0.58 ,0.6,0.7,0.8]\n",
    "for i in THRESHOLD:\n",
    "    preds = np.where(model.predict(X_test).ravel() > i, 1, 0)\n",
    "    print(i)\n",
    "    df_thresh = pd.DataFrame(data=[accuracy_score(y_test, preds), recall_score(y_test, preds),\n",
    "                       precision_score(y_test, preds), roc_auc_score(y_test, preds)], \n",
    "                 index=[\"accuracy\", \"recall\", \"precision\", \"roc_auc_score\"], columns = [\"Scores\"])\n",
    "    display(df_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "predicted = np.where(predicted > THRESHOLD ,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a2052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Actual\": y_test.ravel(),\n",
    "    \"Predicted\": preds.ravel()\n",
    "}, index = data.index[-len(y_test): ]) \n",
    "\n",
    "# Show the DataFrame's head\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39007475",
   "metadata": {},
   "source": [
    "### classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2449f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "print(classification_report(y_test,predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3bf8fa",
   "metadata": {},
   "source": [
    "### Plot  roc_curve and auc metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "train_predictions = model.predict(X_train, batch_size=1000)\n",
    "test_predictions = model.predict(X_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eaee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROC curve and AUC for the training set\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, train_predictions)\n",
    "auc_train = auc(fpr_train, tpr_train)\n",
    "auc_train = round(auc_train, 4)\n",
    "\n",
    "# Calculate the ROC curve and AUC for the testing set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, test_predictions)\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "auc_test = round(auc_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the fpr and tpr results\n",
    "roc_df_train = pd.DataFrame({\"FPR Train\": fpr_train, \"TPR Train\": tpr_train,})\n",
    "\n",
    "roc_df_test = pd.DataFrame({\"FPR Test\": fpr_test, \"TPR Test\": tpr_test,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dcc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ROC Curves\n",
    "roc_df_train.hvplot(\n",
    "    x=\"FPR Train\",\n",
    "    y=\"TPR Train\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Train ROC Curve (AUC={auc_train})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df_test.hvplot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7168819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9986e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ee5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4477ac50",
   "metadata": {},
   "source": [
    "#### 3. Model 3......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f232e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da198759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7ca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a224af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd0ba72",
   "metadata": {},
   "source": [
    "#### 4. Model 4......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666566bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72fe94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f485ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "479a52ad",
   "metadata": {},
   "source": [
    "#### 5. Model 5 ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d88587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd251976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf5742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04e43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2cc75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86058300",
   "metadata": {},
   "source": [
    "### IV. ANALYSIS AND EVALUATION (TEAM WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076208d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dce041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df8368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c9b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c001ff1f",
   "metadata": {},
   "source": [
    "### V. DEPLOYING MODEL (TEAM WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488273b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071d27ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989db957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae5f577c",
   "metadata": {},
   "source": [
    "### VI. CONCLUSION (TEAM WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020ad81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
